FROM nvcr.io/nvidia/tensorrt:20.08-py3
RUN sed -i -e 's/archive.ubuntu.com/free.nchc.org.tw/' /etc/apt/sources.list

# CUDA 10.2
ENV DEBIAN_FRONTEND noninteractive
RUN apt-get update && apt-get install -y \
    ca-certificates cmake wget sudo protobuf-compiler \
    libprotobuf-dev python3-pip curl vim zip && \
    rm -rf /var/lib/apt/lists/*
    # cuda-libraries-10-0

# # create a non-root user
# ARG USER_ID=1000
# # RUN useradd -m --no-log-init --system  --uid ${USER_ID} appuser -g sudo
# RUN groupadd -r appuser && useradd -r -g appuser -m -d /home/appuser -s /sbin/nologin/ -c "Docker Image User" appuser
# RUN echo '%sudo ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers
# USER appuser
# WORKDIR /home/appuser
# ENV PATH="/home/appuser/.local/bin:${PATH}"

RUN /usr/bin/python3 -m pip install --upgrade pip

# RUN wget https://bootstrap.pypa.io/get-pip.py && \
#     python3 get-pip.py --user && \
#     rm get-pip.py

## install Pytorch
RUN pip3 install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html
# RUN pip3 install torch torchvision -f https://download.pytorch.org/whl/torch_stable.html

## Onnxruntime
RUN pip3 install onnx==1.7.0 onnxruntime-gpu==1.1.2 
### RUN pip3 install --user onnx==1.7.0 onnxruntime==1.4.0

## Install opencv
RUN pip3 install opencv-python==4.1.2.30 && pip3 install opencv-python-headless==4.1.2.30 
# RUN sudo apt-get update -y && sudo apt-get install -y libgl1-mesa-dev libglib2.0-0

# ### Upgrade Cmake version
# RUN wget http://www.cmake.org/files/v3.13/cmake-3.13.0.tar.gz \
# && tar xpvf cmake-3.13.0.tar.gz cmake-3.13.0/ && rm cmake-3.13.0.tar.gz && cd cmake-3.13.0 \
# && ./configure && make -j8
# RUN echo 'export PATH=/workspace/cmake-3.13.0/bin/:$PATH' >> ~/.bashrc && /bin/bash -c "source ~/.bashrc"

#### nvidia 
# # Install Cmake
# RUN cd /tmp && \
#     wget https://github.com/Kitware/CMake/releases/download/v3.14.4/cmake-3.14.4-Linux-x86_64.sh && \
#     chmod +x cmake-3.14.4-Linux-x86_64.sh && \
#     ./cmake-3.14.4-Linux-x86_64.sh --prefix=/usr/local --exclude-subdir --skip-license && \
#     rm ./cmake-3.14.4-Linux-x86_64.sh

# Install cuda-libraries-10-0 
RUN sudo apt-get update && sudo apt-get install -y software-properties-common && \
sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub && \ 
add-apt-repository "deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/ /" && \
sudo apt-get update && sudo apt-get -y install cuda-libraries-dev-10-0

# Install zsh
# RUN sudo apt-get update && sudo apt-get install -y zsh && sh -c "$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)" 
# RUN chsh -s /bin/zsh 
RUN ["apt-get", "update"]
RUN ["apt-get", "install", "-y", "zsh"]
RUN wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | zsh || true
# RUN echo 'export PATH=/workspace/cmake-3.13.0/bin/:$PATH' >> ~/.zshrc && /bin/zsh -c "source ~/.zshrc"

# Insatll Onnx2trt
RUN git clone --recurse-submodules https://github.com/onnx/onnx-tensorrt.git && \
cd onnx-tensorrt && git checkout release/7.0 && cmake . && make && make install 
ENV LD_LIBRARY_PATH=$PWD:$LD_LIBRARY_PATH

# Install trtis client & matplotlib
RUN pip3 install tensorrtserver matplotlib